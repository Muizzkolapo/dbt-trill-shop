# Sample configuration file for dbt PR Review Agent
# Copy this to .dbt-pr-agent.toml in your project root

[project]
name = "my-dbt-project"
target_path = "target"
artifacts_path = "target"

# GitHub configuration (optional)
[github]
# token = "ghp_xxxxxxxxxxxx"  # Can also use GITHUB_TOKEN env var
# repo = "owner/repo"

# LLM configuration
[llm]
# Provider options: "openai", "anthropic", "ollama"
provider = "openai"

# API key - prefer using environment variables:
# - OPENAI_API_KEY for OpenAI
# - ANTHROPIC_API_KEY for Anthropic
# api_key = "sk-..."  # Not recommended to store here

# Base URL (optional, for custom endpoints or local models)
# base_url = "http://localhost:11434"  # For Ollama

# Model selection
# OpenAI: "gpt-4-turbo-preview", "gpt-4", "gpt-3.5-turbo"
# Anthropic: "claude-3-opus", "claude-3-sonnet", "claude-3-haiku"
# Ollama: "llama3", "mixtral", "codellama"
default_model = "gpt-4-turbo-preview"

# Request parameters
temperature = 0.3  # Lower = more consistent, Higher = more creative
max_tokens = 4096
timeout_seconds = 60
max_retries = 3

# Rate limiting
[llm.rate_limit]
requests_per_minute = 60
tokens_per_minute = 90000

# Agent-specific configuration
[agents]

# Impact Analysis Agent
[agents.impact]
enabled = true
use_llm = true  # Use LLM for enhanced analysis
max_depth = 5   # Maximum depth for downstream impact analysis

# Quality Validation Agent
[agents.quality]
enabled = true
use_llm = true
min_test_coverage = 0.8  # Minimum acceptable test coverage (80%)
strict_mode = false      # Enforce strict SQL standards

# Performance & Cost Agent
[agents.performance]
enabled = true
use_llm = true
cost_threshold = 0.1     # Alert if cost increases by more than 10%
performance_threshold = 0.2  # Alert if performance degrades by more than 20%

# Warehouse-specific settings
[warehouse]
type = "bigquery"  # Options: "bigquery", "snowflake", "databricks", "redshift"

# BigQuery specific
[warehouse.bigquery]
project_id = "my-gcp-project"
dataset_id = "analytics"
location = "US"

# Cost estimates (per TB)
query_cost = 5.0
storage_cost = 0.02

# Snowflake specific
[warehouse.snowflake]
account = "my-account"
warehouse_size = "MEDIUM"
# Cost estimates (per credit)
credit_cost = 2.0

# Reporting configuration
[reporting]
# Default output format: "json", "markdown", "text"
default_format = "markdown"

# Include these sections in reports
include_executive_summary = true
include_risk_matrix = true
include_cost_breakdown = true
include_optimization_tips = true

# Risk thresholds
[risk]
# Models affected thresholds
critical_model_threshold = 50
high_model_threshold = 20
medium_model_threshold = 10

# Cost increase thresholds (percentage)
critical_cost_threshold = 50.0
high_cost_threshold = 25.0
medium_cost_threshold = 10.0

# Execution settings
[execution]
# Run agents in parallel for faster analysis
parallel_agents = true

# Cache artifact loading for better performance
cache_artifacts = true

# Timeout for entire PR analysis (seconds)
analysis_timeout = 300

# Logging
[logging]
# Log level: "error", "warn", "info", "debug", "trace"
level = "info"

# Log format: "pretty", "json"
format = "pretty"

# Output file (optional)
# file = "dbt-pr-agent.log"